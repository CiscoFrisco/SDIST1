%%%%%%%%%%%%%%%%%%%%%%%%%%
% USFD Academic Report Template
% Prof. Roger K. Moore
% University of Sheffield
% 30 July 2018
%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[11pt,oneside]{book}
\usepackage[margin=1.2in]{geometry}
\usepackage[toc,page]{appendix}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{lipsum}
\usepackage{caption}
\usepackage[portuguese]{babel}
\usepackage{setspace}
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\setcounter{chapter}{1}% Not using chapters, but they're used in the counters

\begin{document}

\begin{titlepage}

\begin{center}
{\LARGE Universidade do Porto}\\[1.5cm]
\linespread{1.2}\huge {\bfseries Serverless Distributed Backup Service}\\[1.5cm]
\linespread{1}
\includegraphics[width=7.5cm]{feup.png}\\[1cm]
{\large Pedro Fernandes \textbf{up201603846}@fe.up.pt}\\
{\large Francisco Filipe \textbf{up201604601}@fe.up.pt}\\[1cm]
{\large \emph{Unidade Curricular:} Sistemas Distribuídos}\\
{\large \emph{Docente:} Diana Guimarães}\\
{\large \emph{Turma:} MIEIC02}\\
{\large \emph{Grupo:} 8}\\[2cm]

\large \today
\end{center}

\end{titlepage}

% -------------------------------------------------------------------
% Contents, list of figures, list of tables
% -------------------------------------------------------------------

\doublespacing
\tableofcontents
\singlespacing

% -------------------------------------------------------------------
% Main sections (as required)
% -------------------------------------------------------------------

\mainmatter

\section{Introdução}
\paragraph{}
Este relatório foi desenvolvido no âmbito do primeiro trabalho prático da 
Unidade Curricular de Sistemas Distribuídos. O seu objetivo é clarificar 
alguns dos aspetos principais da nossa implementação, nomeadamente os seguintes:
\begin{itemize}
    \item \textbf{Instruções de Compilação e Execução:} As instruções necessárias
    para compilar e executar corretamente o programa desenvolvido, tanto em Windows
    como em Linux. Também está presente nesta secção a descrição dos scripts 
    implementados, que ajudam na demonstração do trabalho.
    \item \textbf{Execução Concorrente de Protocolos:} Descrição detalhada dos
    mecanismos e estruturas de dados utilizadas no desenvolvimento deste trabalho, 
    que permitem a execução concorrente dos diferentes protocolos. Esta descrição é
    acompanhada de alguns excertos do código fonte para ajudar a compreender a 
    implementação desenvolvida.
    \item \textbf{Melhorias Implementadas:} Descrição de cada uma das melhorias 
    propostas, da solução pensada e da implementação desenvolvida.
    
\end{itemize}     

\pagebreak

\section{Instruções de Compilação e Execução}

\subsection{Compilação}
\paragraph{}
    Para compilar o trabalho desenvolvido, tanto em Windows como em Linux, apenas é 
    necessário mudar o diretório atual para a pasta \textit{/src} e executar o seguinte
    comando:
    \begin{lstlisting}
        javac *.java
    \end{lstlisting}

\subsection{Execução}

\paragraph{}
    Para executar o trabalho são necessários seguir os 3 próximos passos:
    
    \subsubsection{Iniciar o Registo RMI}
    \paragraph{}
    Visto que este trabalho implementa a interface \textit{RemoteMethodInvocation} (RMI) de
    Java, para o testar corretamente é necessário ainda iniciar o registo RMI com:
    \begin{lstlisting}
        //Linux
        rmiregistry &
        //Windows
        start rmiregistry
    \end{lstlisting}
    
    \subsubsection{Executar os Peers}
    \paragraph{}
    O comando de execução dos \textit{peers} é o seguinte:
    \begin{lstlisting}
       java Peer <protocol_version> <peerID> <peer_ap> <MCaddress> <MCport> <MDBaddress> <MDBport> <MDRaddress> <MDRport>
    \end{lstlisting}
    \begin{itemize}
        \item protocol\_version: Versão do protocolo compatível com o \textit{peer}.
        \item peerID: Identificador úncico de um \textit{peer}.
        \item peer\_ap: Ponto de acesso do objeto do RMI.
        \item MCadress: Endereço IP do canal multicast de controlo.
        \item MCport: Porta do canal multicast de controlo.
        \item MDBadress: Endereço IP do canal multicast de backup.
        \item MDBport: Porta do canal multicast de backup.
        \item MDRadress: Endereço IP do canal multicast de restore.
        \item MDRport: Porta do canal multicast de restore.
    \end{itemize}
        Os endereços IP multicast acima utilizados devem estar entre os valores 224.0.0.0 e
        224.0.0.255 que são os endereços multicast reservados para redes locais.
    \paragraph{}
        Dentro da pasta \textit{/scripts} existem ainda 3 scritps (1 de Linux e 2 de Windows) que
        permitem a execuçãode vários \textit{peers} de uma só vez. Para isso só é necessário
        executar os comandos:
        \begin{lstlisting}
            //Linux
            ./start.sh <protocol_version> <num_peers> <startID>
            //Windows
            win_start  <protocol_version> <num_peers> <startID> //or
            win_start_rev <protocol_version> <num_peers> <startID>
        \end{lstlisting}
        \begin{itemize}
            \item protocol\_version: Versão do protocolo compatível com o \textit{peer}.
            \item num\_peers: Número de \textit{peers} a executar.
            \item startID: ID a partir do qual vão ser criados novos peers.
        \end{itemize}
        A única diferença entre os dois scripts de Windows é a ordem pela qual os Peers
        executam. O script win\_start inicia os scripts por ID ascendente enquanto o 
        win\_start\_rev vai iniciando por ordem descendente.
    
    \subsubsection{Executar a TestApp}
    O comando de execução da \textit{TestApp} é o seguinte:
    \begin{lstlisting}
        java TestApp <peer_ap> <operation> <opnd_1> <opnd_2> 
    \end{lstlisting}
    \begin{itemize}
        \item preer\_ap: Ponto de acesso do \textit{peer}.
        \item operation: Protocolo a ser executado.
        \item opnd\_1: Pode ser o diretório do ficheiro a dar BACKUP/RESTORE/DELETE ou,
        no caso do protocolo RECLAIM, o espaço máximo de disco (em Kbytes).
        \item opnd\_2: Utilizado no protocolos BACKUP/BACKUPENH e especifica o
        \textit{replication degree}.
    \end{itemize}

    \paragraph{}
    Tal como na execução dos \textit{peers} também aqui foram desenvolvidos scripts para
    Windows e Linux que testam: vários protocolos BACKUP concorrentes, vários protocolos 
    RESTORE concorrentes e vários protocolos diferentes concorrentes.
    \begin{lstlisting}
        //Linux
        ./multiple_backup.sh [enhancement=true]
        ./multiple_restore.sh [enhancement=true]
        ./multiple_protocols.sh [enhancement=true]

        //Windows
        backup [enhancement=true]
        restore [enhancement=true]
        protocols [enhancement=true]
    \end{lstlisting}
    Este script tem um argumento opcional que, caso esteja presente,indica que os 
    protocolos devem executar a versão melhorada.

\pagebreak

\section{Execução Concorrente de Protocolos}
\paragraph{}
    De forma a garantir a execução concorrente de protocolos da melhor forma
    possível foram tomadas algumas medidas tendo em conta os seguintes fatores:
    \begin{itemize}
        \item  Dentro de um protocolo há várias mensagens a serem enviadas ao mesmo tempo.
        \item  Alguns protocolos requerem a gestão de recursos "partilhados" (recursos que
        apesar de serem instanciados cada um no seu \textit{peer}, são iguais em todos estes e,
        portanto, têm de ser coerentes).
        \item  Um \textit{peer} pode ter que guardar/enviar vários chunks ao mesmo tempo.
    \end{itemize}
 
\paragraph{}
    O primeiro passo na implementação da concorrência foi a utilização de
    \textit{threads}. Para tal decidimos utilizar a classe 
    \textit{ScheduledThreadPoolExecutor}. Esta classe facilita bastante a 
    implementação de \textit{multi-threading} uma vez que já implementa mecanismos
    de baixo nível e os disponibiliza a um alto nível. Um dos aspetos que nos
    levou a optar pelo uso desta classe foi o facto de esta reciclar 
    \textit{threads}. A criação e destruição de \textit{threads} é um processo
    dispendioso e, portanto, uma funcionalidade destas aumenta substancialmente a
    performance do nosso traalho. Outro aspeto também muito importante a ter em
    consideração foi o facto de ser possível agendar a execução de novas 
    \textit{threads} sem comprometer a execução da \textit{thread} atual. A outra
    alternativa a esta opção na nossa perspetiva seria o uso de 
    \textit{Thread.sleep()}, que resultaria numa pior performance uma vez que bloqueia
    a \textit{thread} atual.
\paragraph{}
    O desenho da implementação \textit{multi-threading} foi de acordo com a 
    seguinte estrutura:
    \begin{itemize}
        
        \item Quando um protocolo é invocado, o \textit{initiator peer} faz a
        chamada à função responsável por esse protocolo. 
        \item Em todos os protocolos (à exceção do protocolo STATE) é iniciada a 
        \textit{thread MesssageSenderThread} que, ao receber como parâmetros a
        mensagem a enviar, o canal por onde enviar e o peer que a envia, envia a
        mensagem para o canal respetivo. Visto que a cada nova mensagem é executada
        uma nova \textit{thread}, é possível o envio concorrente de protocolos.  
        \item Sempre que um peer recebe no seu canal uma mensagem, executa uma nova
        \textit{thread} chamada \textit{MessageReceiverThread}. Esta \textit{thread}
        , recebe os mesmos parâmetros da anterior e é responsável por interpretar 
        que tipo de mensagem foi recebida e executar uma nova \textit{thread} de acordo
        com este tipo. 
        \item Apesar de existirem muitas threads a serem executadas caso haja concorrência de
        protocolo (ou utilizando protocolos com ficheiros maiores), uma vez que se utiliza o 
        \textit{ScheduledThreadPoolExecutor} não há qualquer preocupação quanto a este valor
        uma vez que ele está limitado.
        
        \pagebreak

        \begin{lstlisting}

		switch (messageType) {
		case "PUTCHUNK":
			peer.getScheduler().schedule(new ReceivePutChunkThread(message, length, peer), interval, TimeUnit.MILLISECONDS);
			break;
		case "STORED":
			peer.getScheduler().execute(new ReceiveStoredThread(message, length, peer));
			break;
		case "GETCHUNK":
			peer.getScheduler().execute(new ReceiveGetChunkThread(message, peer));
			break;
		case "CHUNK":
			peer.getScheduler().execute(new ReceiveChunkThread(message, length, peer));
			break;
		case "DELETE":
			peer.getScheduler().execute(new ReceiveDeleteThread(message, peer));
			break;
		case "ACKDELETE":
			peer.getScheduler().execute(new ReceiveAckDeleteThread(message, peer));
			break;
		case "ANNOUNCE":
			peer.getScheduler().execute(new ReceiveAnnounceThread(message, peer));
			break;
		case "REMOVED":
			peer.getScheduler().execute(new ReceiveRemovedThread(message, peer));
			break;
		default:
			break;
		}
        \end{lstlisting}
        
        Analisando o código fonte acima apresentado é possível verificar que para 
        o tratamento de um chunk é executada uma nova thread, permitindo assim o
        processamento simultâneo de vários chunks.  
        
        
    \end{itemize}

\paragraph{}
    Em relação às estruturas de dados utilizadas para guardar \textit{chunks},
    canais de comunicação e  
    mensagens proveninentes de outros \textit{peers}, optámos pela utilização de
    \textit{ConcurrentHashMap} em vez de \textit{HashMap}. A principal vantagem da
    primeira reside no facto de assegurar o correto funcionamento na presença de 
    várias \textit{threads}, algo que não é assegurado com a utilização de 
    \textit{HashMap}. Visto que este trabalho utiliza em grande parte o conceito de 
    \textit{multi-threading}, esta foi a escolha óbvia a fazer.
\pagebreak 

\section{Melhorias Implementadas}
    Neste trabalho foram propostas melhorias aos protocolos BACKUP, RESTORE e 
    DELETE. Todas elas foram implementadas com sucesso e, como tal, iremos descrever
    nos próximos parágrafos as soluções desenvolvidas de uma forma mais detalhada. 

\subsection{Protocolo Backup}

\subsubsection{Melhoria Proposta}
\paragraph{}
Implementar uma mudança ao protocolo que previna o rápido consumo de espaço dos 
\textit{peers}, diminue o registo de atividade quando estes estiverem cheios e 
assegure o \textit{replication degree} desejado. Esta melhoria tem de operar
de forma correta com o protocolo da versão \textit{vanilla}.

\subsubsection{Implementação}
\paragraph{}
    Na versão \textit{vanilla} deste protocolo, apesar de ser garantido o 
    \textit{replication degree}, o número de \textit{chunks} guardados nos 
    \textit{peers} do sistema pode ser superior a este valor, visto que ele
    guarda em todos os \textit{peers} que estejam à escuta. Isto faz com que, 
    caso haja 100 \textit{peers} à escuta e um deles faça BACKUP de um ficheiro
    com \textit{replication degree} de apenas 2, 99 \textit{peers} vão guardar os 
    \textit{chunks} desse ficheiro sendo que 97 deles estão a realizar
    trabalho desnecessário.
\paragraph{}
    Na melhoria deste protocolo utilizámos a nosso favor a classe \textit{Storage}
    implementada, mais concretamente o \textit{ConcurrentHashMap confirmationMessages}.
    Este tem como chave uma \textit{string} que combina o ID do ficheiro com o número
    do \textit{chunk} do mesmo. O valor atribuído a cada chave é um 
    \textit{ArrayList} de inteiros que representam o ID do \textit{peer} que 
    enviou a mensagem STORED desse mesmo chunk após a execução do protocolo BACKUP. 
    Assim, para saber qual o \textit{replication degree} atual de um \textit{chunk} 
    no sistem, apenas é necessário percorrer o mapa e, quando a chave combinar, 
    obter o número de peers que guardou o \textit{chunk} recorrendo para isso ao 
    tamanho do \textit{ArrayList} respetivo.
\paragraph{}
    A implementação do protocolo \textit{vanilla} não permitia a um \textit{peer}
    conhecer quantos chunks já tinham sido guardados no sistema. Para contornar 
    esta adversidade foram realizadas três alterações ao protocolo:
    \begin{itemize}
        \item Antes de executar a \textit{thread} de tratamento de mensagens do tipo
        PUTCHUNK, é adicionado um \textit{delay} aleatório entre 0 e 400ms.
        \item Antes de guardar um \textit{chunk} é verificado o seu
        \textit{replication degree} atual.
        \item O envio da mensagem STORED é realizado antes do \textit{peer}
        guardar o \textit{chunk} que recebeu e não após.
    \end{itemize}

\paragraph{}
    A primeira alteração foi implementada recorrendo a um método da interface
    \textit{ScheduledExecutorService} que permite agendar a execução de uma
    \textit{thread}. Como são vários os \textit{peers} que vão estar a
    tratar, paralelamente, as suas mensagens PUTCHUNK, ao agendarmos a execução
    das \textit{thread}, minimizamos a concorrência sem comprometer a performance.
\paragraph{}
    Visto que é necessário garantir um determinado \textit{replication degree},
    antes de guardar um chunk verifica-se se o seu \textit{replication degree}
    desejado já foi atingido. Se sim, aborta-se a escrita do ficheiro. O facto de
    a execução das threads ser agendada e a concorrência minimizada ajuda nesta 
    verificação pois os valores do \textit{replication degree} conseguem ser mais
    atuais do que seriam caso a execução fosse imediata.
\paragraph{}
    A escrita de um \textit{chunk} num peer consome algum tempo precioso. Se
    realizarmos esta operação antes de enviar a mensagem STORED, podemos ter muitos
    \textit{peers} a guardar um \textit{chunk} desnecessariamente pois fazem-no
    antes de atualizar o valor do \textit{replication degree}. Ao enviar o STORED
    primeiro, estamos a atualizar este valor e, só depois, a guardar efetivamente o
    \textit{chunk}, conseguindo manter o valor do \textit{replication degree} o
    mais atual possível para todos os peers. 
 
\pagebreak

\subsection{Protocolo Restore}

\subsubsection{Melhoria Proposta}
\paragraph{}
Implementar uma mudança ao protocolo de forma a que apenas o 
\textit{initiator peer} receba os chunks enviados pelos restantes peers. 
Esta implementação deve interoperar com a versão \textit{vanilla} e também
utilizar TCP.

\subsubsection{Implementação}
\paragraph{}
    Na implementação deste protocolo na versão \textit{vanilla} é utilizado um
    canal multicast para enviar os \textit{chunks} pedidos pelo
    \textit{initiator peer}. Isto significa que todos os \textit{peers} recebem
    os chunks, sendo que se estes últimos forem de grande tamanho diminuem a 
    performance dos \textit{peers}. Para desenvolver uma melhoria que recebesse 
    crédito total tivemos que pensar numa estratégia que resolvesse este 
    problema utilizando TCP. 
\paragraph{}
    Tendo isto em consideração a melhoria desenvolvida baseou-se no seguinte:
    \begin{enumerate}
        \item Quando o \textit{initator peer} executa uma chamada ao método
        \textit{restore} (responsável pelo envio de todas as mensagens GETCHUNK,
        espera das mensagens CHUNK e restauro do ficheiro pedido), são iniciados:
        \begin{itemize}
            \item Um socket de comunicação por onde os \textit{peers} enviam os
            chunks pedidos.
            \item Uma nova \textit{thread} chamada \textit{TCPChunkReceiverThread}
            que fica à escuta de novas mensagens enquanto o socket estiver
            aberto.
            \item Um semáforo com o valor inicial igual ao número de \textit{chunks}
            do ficheiro. Este semáforo foi implementado utilizando a classe
            \textit{CountDownLatch}. Este semáforo é utilizado para controlar
            o número de \textit{chunks} que falta restaurar.
        \end{itemize}
        \paragraph{}
        Esta mensagem GETCHUNK passou a enviar também o endereço IP do \textit{initiator peer} e 
        a porta do socket instanciado por este. Desta forma, os \textit{peers} que efetuarem a 
        comunicação via TCP conseuguem estabelecer a comunicação com o \textit{initator peer}
        através de um socket que utilize estes atributos como argumentos.
        \item De seguida são enviadas todas as mensagens GETCHUNK de uma só vez e,
        através da chamada ao método \textit{await} da classe \textit{CountDownLatch},
        é bloqueado o \textit{initiator peer}. Este só retorna à sua execução assim
        que o semáforo chegar a 0 e, portanto, sejam restaurados todos os 
        \textit{chunks}.
        \item Assim que uma mensagem GETCHUNK chega a um novo \textit{peer}, se
        este tiver feito backup do \textit{chunk} pedido, executa uma nova
        \textit{thread} chamada \textit{TCPChunkSenderThread} que vai enviar pelo 
        canal TCP um inteiro que representa o número do \textit{chunk} que 
        pretende restaurar. 
        \item A \textit{thread TCPChunkReceiverThread} ao receber o número do 
        \textit{chunk} verifica se este já foi previamente restaurado. De seguida
        envia uma resposta booleana ao \textit{peer} que enviou o número do 
        \textit{chunk} indicando se pode ou não prosseguir com o envio do 
        \textit{chunk} em si.
        \item Ao receber esta resposta, a \textit{thread TCPChunkSenderThread} 
        age de acordo com a mesma. Isto é, caso indique que não deve prosseguir
        com o restauro é terminada, senão envia pelo canal TCP a mensagem CHUNK
        contendo o \textit{chunk} que o \textit{initiator peer} pediu.
        \item Por fim a \textit{thread TCPChunkReceiverThread} ao receber a mensagem
        CHUNK, separa os seus parâmetros e guarda toda a informação que lhe for útil,
        isto é:
        \begin{itemize}
            \item Atualiza no \textit{ConcurrentHashMap chunkMessages} o número
            de mensagens do tipo CHUNK que já recebeu para um determinado \textit{chunk}
            (utilizado para prevenir o excesso de mensagens do tipo CHUNK no 
            \textit{initiator peer}).
            \item Guarda o conteúdo do \textit{chunk} enviado num \textit{ConcurrentHashMap} conhecido
            como \textit{restoredFiles}. Este mapa, tal como na melhoria anterior, 
            tem como chave uma \textit{string} que combina o ID do ficheiro com
            o número do \textit{chunk}. O valor atribuído a cada chave é o 
            conteúdo em bytes desse \textit{chunk}.
            \item Assinala que restaurou mais um \textit{chunk} atualizando o 
            valor do semáforo.
        \end{itemize}
        \item Este processo é cíclico desde o ponto 2 ao ponto 5 e só termina quando
        o semáforo desbloquear o \textit{initiator peer}. Quando tal acontecer é
        fechado o socket inicializado no ponto 1 e invocada uma função responsável
        pela criação do ficheiro no sistema.
        \item Assim que esta última função terminar a sua execução, o 
        \textit{initiator peer} termina a sua execução, terminando assim o protocolo
        RESTOREENH.
    \end{enumerate}



\pagebreak

\subsection{Protocolo Delete}

\subsubsection{Melhoria Proposta}
\paragraph{}
Implementar uma mudança ao protocolo de forma a que \textit{peers} que tenham
feito BACKUP a chunks de um ficheiro e, no momento de execução do protocolo 
DELETE deste ficheiro, estejam desligados também possam eliminar os seus chunks 
assim que estejam ativos.

\subsubsection{Implementação}
\paragraph{}
    Numa primeira abordagem a ideia para esta implementação era criar um ficheiro
    em todos os \textit{peers} chamado de tasks.txt com a informação necessária
    dos ficheiros a eliminar da sua classe \textit{Storage}. Este ficheiro consistiría
    numa série de linhas em que cada uma teria a seguinte estrutura:
    \begin{equation}
        DELETE \quad <fileID>
    \end{equation}
    Desta forma, quando um peer iniciasse a sua execução, ao percorrer este ficheiro eliminava os 
    \textit{chunks} respetivos. No entanto, foi apenas após testar nos computadores da 
    faculdade que nos apercebemos que esta solução não está corretamente implementada pois só funciona 
    localmente.


\paragraph{}
    Desta forma optámos por uma outra abordagem que funcionasse em todos os casos
    e não apenas localmente. Para isso decidimos criar mais duas mensagens de comunicação 
    entre \textit{peers}:
    \begin{itemize}
        \item \textbf{ANNOUNCE:} Esta mensagem é executada sempre que um 
        \textit{peer} começa a sua execução. Desta forma todos os \textit{peers} ativos 
        conseguem saber quando um outro \textit{peer} é iniciado.
        \item \textbf{ACKDELETE:} Esta mensagem é executada sempre que o protocolo DELETE
        é executado num \textit{peer}, sinalizando aos restantes que um \textit{peer} acabou 
        de apagar todos os \textit{chunks} de um ficheiro no seu sistema.
    \end{itemize}

\paragraph{}
    Com estas mensagens implementadas o novo protocolo foi de acordo com a seguinte estrutura:
    \begin{enumerate}
        \item Quando um \textit{peer} implementa o protocolo DELETE envia uma mensagem para 
        os restantes \textit{peers} dizendo qual o ficheiro que pretende eliminar do sistema.
        \item Os \textit{peers} que estiverem ativos, ao receberem esta mensagem eliminam os
        \textit{chunks} respetivos e, de seguida enviam uma mensagem do tipo ACKDELETE contendo
        o ID do ficheiro que acabaram de eliminar. 
        \item Esta mensagem é recebida por todos os \textit{peers} que imediatamente executam a
        \textit{thread ReceiveAckDeleteThread}. Esta \textit{thread} está encarregue de 
        atualizar os valores dos atributos \textit{confirmationMessages} e \textit{deleteAcks}. 
        O primeiro consiste num mapa que a cada \textit{chunk} de um ficheiro guarda os 
        \textit{peers} que o contêm. O segundo, também um mapa, guarda os \textit{peers} que já 
        eliminaram um determinado ficheiro. Desta forma, apenas é necessário eliminar os 
        \textit{peers} que executaram o protocolo DELETE do primeiro atributo e adicionar ao 
        segundo.
        \item Caso um \textit{peer} esteja desligado no momento em que é invocado o protocolo
        DELETE, no momento em que este passar a estar ativo é enviada uma mensagem ANNOUNCE 
        contendo o ID do \textit{peer} que acabou de se ligar.
        \item Os restantes \textit{peers} ao receberem esta mensagem executam a 
        \textit{thread ReceiveAnnounceThread} que, recorrendo ao método \textit{getTasks} 
        verificam se o \textit{peer} que se ligou tem \textit{chunks} guardados que já foram
        eliminados. Este método retorna um \textit{ArrayList\textless String\textgreater} 
        contendo os IDs desses ficheiros.
        \item Depois de obter os IDs dos ficheiros, através de um ciclo, é enviada uma 
        mensagem DELETE que, ao ser recebida pelo \textit{peer} que acabou de se ligar, faz 
        com que este atualize o conteúdo da sua classe \textit{Storage} eliminando os 
        \textit{chunks} necessários.
    \end{enumerate}


\end{document}